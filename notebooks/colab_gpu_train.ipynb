{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7ed58f",
   "metadata": {},
   "source": [
    "# Colab GPU Training for this repo (Transformer + Lightning + MLflow)\n",
    "\n",
    "This notebook is meant to be pasted/run in **Google Colab** (GPU runtime) to train this repo on a GPU and keep artifacts in Google Drive.\n",
    "\n",
    "It also doubles as a quick VS Code notebook sanity-check template.\n",
    "\n",
    "> Tip: In Colab go to **Runtime → Change runtime type → GPU** before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Minimal notebook skeleton (idempotent cell)\n",
    "seed = 42\n",
    "msg = \"hello from notebook\"\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add(1, 2), seed, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee62e96",
   "metadata": {},
   "source": [
    "## 2) Verify environment (Python, GPU, paths)\n",
    "\n",
    "This prints Python info and checks whether CUDA is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "print(\"python:\", sys.version)\n",
    "print(\"executable:\", sys.executable)\n",
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch:\", torch.__version__)\n",
    "    print(\"cuda available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"gpu:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"Torch import failed:\", e)\n",
    "\n",
    "try:\n",
    "    import lightning\n",
    "    print(\"lightning:\", lightning.__version__)\n",
    "except Exception as e:\n",
    "    print(\"Lightning import failed:\", e)\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    print(\"mlflow:\", mlflow.__version__)\n",
    "except Exception as e:\n",
    "    print(\"MLflow import failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179b9bd",
   "metadata": {},
   "source": [
    "## 3) Sanity-check stdout/stderr\n",
    "\n",
    "This intentionally throws and catches an exception to show tracebacks in notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"stdout: hello\")\n",
    "\n",
    "try:\n",
    "    1 / 0\n",
    "except Exception as e:\n",
    "    print(\"caught error:\", repr(e))\n",
    "\n",
    "print(\"still running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08667e53",
   "metadata": {},
   "source": [
    "## 4) Persist and reload notebook state (basic I/O)\n",
    "\n",
    "Writes a small JSON file and reads it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "state_path = Path(\"data/state.json\")\n",
    "\n",
    "state = {\"seed\": seed, \"msg\": msg, \"sum\": add(10, 20)}\n",
    "state_path.write_text(json.dumps(state, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "loaded = json.loads(state_path.read_text(encoding=\"utf-8\"))\n",
    "assert loaded[\"sum\"] == 30\n",
    "loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844af7d7",
   "metadata": {},
   "source": [
    "## 5) Add a simple unit test cell\n",
    "\n",
    "Uses `unittest` in a notebook-friendly way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5767007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "def add2(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "class TestAdd(unittest.TestCase):\n",
    "    def test_add(self):\n",
    "        self.assertEqual(add2(1, 2), 3)\n",
    "\n",
    "    def test_zero(self):\n",
    "        self.assertEqual(add2(0, 0), 0)\n",
    "\n",
    "\n",
    "unittest.main(argv=[\"\"], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02f3a7",
   "metadata": {},
   "source": [
    "## 6) Capture output to a file and display it\n",
    "\n",
    "Writes a simple log file and prints the last lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"logs\").mkdir(exist_ok=True)\n",
    "log_path = Path(\"logs/run.log\")\n",
    "\n",
    "with log_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"starting run\\n\")\n",
    "    f.write(f\"seed={seed}\\n\")\n",
    "    f.write(\"done\\n\")\n",
    "\n",
    "print(\"Last 10 lines:\")\n",
    "print(\"\\n\".join(log_path.read_text(encoding=\"utf-8\").splitlines()[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d7008",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Colab section (GPU training + MLflow on Drive)\n",
    "\n",
    "The cells below are specifically for Google Colab.\n",
    "\n",
    "They will:\n",
    "\n",
    "1. Mount Google Drive\n",
    "2. Clone your repo\n",
    "3. Install requirements\n",
    "4. Point MLflow tracking to Drive (so runs persist)\n",
    "5. Run training on GPU\n",
    "\n",
    "> MLflow UI: On Colab, a full web UI is awkward to expose. The typical workflow is: log to Drive, then run `mlflow ui` locally against that same `mlruns` folder (or use a remote tracking server)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b94189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Colab) 1) Mount Drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06619c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Colab) 2) Clone repo\n",
    "# Replace with your repo URL.\n",
    "REPO_URL = \"https://github.com/<owner>/<repo>.git\"\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"AttentionIsAllYouNeed\"):\n",
    "    !git clone {REPO_URL} AttentionIsAllYouNeed\n",
    "%cd AttentionIsAllYouNeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Colab) 3) Install dependencies\n",
    "!pip -q install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852724ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Colab) 4) Point MLflow + data to Drive for persistence\n",
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = Path(\"/content/drive/MyDrive\")\n",
    "PROJECT_ROOT = DRIVE_ROOT / \"attention_is_all_you_need\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\" / \"wmt14_en_de\"\n",
    "MLRUNS_DIR = PROJECT_ROOT / \"mlruns\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MLRUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"MLRUNS_DIR:\", MLRUNS_DIR)\n",
    "\n",
    "# Copy your prepared dataset folder into Drive once.\n",
    "# If you already have a local folder in the repo, you can copy it like:\n",
    "# !cp -r data/raw/wmt14_en_de/* \"{DATA_DIR}/\"\n",
    "\n",
    "# Check expected files\n",
    "for fn in [\"train.en.bpe32000\", \"train.de.bpe32000\", \"valid.en.bpe32000\", \"valid.de.bpe32000\"]:\n",
    "    print(fn, \"exists?\", (DATA_DIR / fn).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Colab) 5) Run repo smoke test using Drive-backed data\n",
    "import os\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"file:{MLRUNS_DIR}\"\n",
    "\n",
    "# Make sure repo expects data/raw/wmt14_en_de\n",
    "!mkdir -p data/raw/wmt14_en_de\n",
    "!rm -rf data/raw/wmt14_en_de\n",
    "!ln -s \"{DATA_DIR}\" data/raw/wmt14_en_de\n",
    "\n",
    "!python -m src.smoke_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Colab) 6) Train on GPU\n",
    "# This runs the repo entrypoint; it will use MLflow tracking via the env var set above.\n",
    "# Ensure src/train.py has accelerator='gpu' and devices=1 when running in Colab.\n",
    "\n",
    "!python -m src.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7842fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Colab) 7) Export latest MLflow run summary to the repo docs folder\n",
    "!python scripts/export_mlflow_run.py --tracking-uri \"file:{MLRUNS_DIR}\" --experiment attention_is_all_you_need_cpu --out docs/assets/latest_run_summary.json\n",
    "!ls -lah docs/assets | head"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
